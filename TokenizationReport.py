import json
from datetime import datetime
import constants

def generate_tokenization_report(summary_path=None, output_path=None):
    summary_path = summary_path or constants.get_log_path("validate_corpus.summary.json")
    output_path  = output_path or constants.get_log_path( constants.DS_TOKENIZATION_REPORT )

    try:
        with open(summary_path, encoding="utf-8") as f:
            summary = json.load(f)
    except Exception as e:
        print(f"ğŸš¨ Failed to load summary file: {e}")
        return

    # Extract values
    total     = summary.get("total_samples", 0)
    avg_len   = summary.get("avg_input_length", 0)
    mismatch  = summary.get("label_mismatches", 0)
    sarcasm   = summary.get("sarcasm_token_distribution", {})
    tone_lens = summary.get("tone_sequence_lengths", {})

    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # Build interpretation lines
    interp_lines = []

    # Avg input length
    if avg_len < 128:
        interp_lines.append(f"ğŸ”´ Average input length is very low (**{avg_len} tokens**), which may underutilize the modelâ€™s capacity.")
    elif avg_len > 512:
        interp_lines.append(f"ğŸŸ  Average input length exceeds common limits (**{avg_len} tokens**); risk of truncation.")
    else:
        interp_lines.append(f"ğŸŸ¢ Average input length of **{avg_len} tokens** is within optimal range.")

    # Label mismatches
    if mismatch > 0:
        interp_lines.append(f"ğŸ”´ Found **{mismatch}** label mismatches â€” tokenization or mask alignment may be broken.")
    else:
        interp_lines.append(f"ğŸŸ¢ No label mismatches detected â€” masking appears clean.")

    # Sarcasm distribution
    if sarcasm:
        mode = max(sarcasm, key=sarcasm.get)
        interp_lines.append(f"ğŸŸ¢ Sarcasm levels are varied; most frequent token is `{mode}` with `{sarcasm[mode]}` samples.")
    else:
        interp_lines.append("ğŸŸ  Sarcasm token distribution missing â€” tone targets may be absent.")

    # Tone sequence lengths
    if 0 in tone_lens:
        interp_lines.append(f"ğŸŸ  Found samples with **zero tone tags** â€” consider filtering those before training.")
    else:
        most_common_len = max(tone_lens, key=tone_lens.get)
        interp_lines.append(f"ğŸŸ¢ Majority of tone sequences contain `{most_common_len}` tags â€” aligns with typical annotations.")

    # Build Markdown
    md = f"""# ğŸ§ª Tokenized Corpus Validation Report

Generated: **{now}**  
Corpus Path: `{constants.DIR_TRAINING_CORPUS}`  

---

## ğŸ” Corpus Statistics

| Metric | Value |
|--------|-------|
| Total Samples | `{total}` |
| Average Input Length | `{avg_len}` tokens |
| Label Mismatches | `{mismatch}` |
| Sarcasm Token Distribution | `{sarcasm}` |
| Tone Sequence Lengths | `{tone_lens}` |

---

## ğŸ§  Interpretation

""" + "\n".join(f"- {line}" for line in interp_lines) + """

---

## âœ… Verdict

The corpus has been validated.  
Review any orange or red indicators above before training.  

---

## ğŸ“ Artifacts

- Summary: `validate_corpus.summary.json`  
- Log: `validate_corpus.log`

---

*Report generated by Copilot ğŸ§ª*
"""

    try:
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(md)
        print(f"âœ… Markdown report written to: {output_path}")
    except Exception as e:
        print(f"ğŸš¨ Failed to write report: {e}")